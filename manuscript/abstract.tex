\abstract{
Computational methods are in full swing in communication science.
Part of the their promise is to make communication research more reproducible, however, how this plays out in practice has not been systematically studied.
We verify the reproducibility of the entire cohort of 30 substantive and methods papers published in the journal \textit{Computational Communication Research} (CCR), the official journal of the ICA Computational Methods Division with a focus on transparency and hence a high rate of voluntary Open Science participation in the field.
Among these CCR papers, \emph{16} papers do \emph{not} provide data and/or code to allow third-party verification of computational reproducibility.
For the remaining \emph{14} papers, we attempt to execute the code shared by the original authors in a standardized containerized computational environment.
We encounter a variety of issues that preclude us from reproducing the original findings.
In the end, \emph{only 6 papers (20\%)} are classified as at least partially reproducible.
The most common reason for failure among these 14 papers is incomplete sharing of data or code.
We end the paper by discussing strategies for researchers and the subfield to correct for this dismal state of computational reproducibility.
}